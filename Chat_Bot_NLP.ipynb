{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QnA Chatbot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "We will be working with the Babi Data Set from Facebook Research.\n",
    "\n",
    "Full Details: https://research.fb.com/downloads/babi/\n",
    "\n",
    "- Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush,\n",
    "  \"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\",\n",
    "  http://arxiv.org/abs/1502.05698\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_qa.txt','rb') as f:\n",
    "    train_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_qa.txt','rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['Mary', 'moved', 'to', 'the', 'bathroom', '.', 'Sandra', 'journeyed', 'to', 'the', 'bedroom', '.', 'Mary', 'went', 'back', 'to', 'the', 'bedroom', '.', 'Daniel', 'went', 'back', 'to', 'the', 'hallway', '.'], ['Is', 'Daniel', 'in', 'the', 'bathroom', '?'], 'no')\n"
     ]
    }
   ],
   "source": [
    "print(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Creating a Vocabulary of all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = train_data + test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for words in all_data:\n",
    "    vocab = vocab.union(set(words[0]))\n",
    "    vocab = vocab.union(set(words[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vocab.union(set(['yes','no']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Mary', 'the', 'back', 'discarded', 'Daniel', 'there', 'to', 'office', 'football', 'no', 'got', 'went', 'up', 'Sandra', 'journeyed', 'took', 'yes', '?', 'bathroom', 'in', 'travelled', 'milk', 'down', 'grabbed', 'Is', 'dropped', 'John', 'moved', 'garden', 'apple', 'put', '.', 'kitchen', 'picked', 'hallway', 'bedroom', 'left'}\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reserve 0 for pad_sequences\n",
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max lenth of a story\n",
    "all_story_len = [len(data[0]) for data in all_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156\n"
     ]
    }
   ],
   "source": [
    "max_story_len = max(all_story_len)\n",
    "print(max_story_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mary': 1,\n",
       " 'the': 2,\n",
       " 'back': 3,\n",
       " 'discarded': 4,\n",
       " 'daniel': 5,\n",
       " 'there': 6,\n",
       " 'to': 7,\n",
       " 'office': 8,\n",
       " 'football': 9,\n",
       " 'no': 10,\n",
       " 'got': 11,\n",
       " 'went': 12,\n",
       " 'up': 13,\n",
       " 'sandra': 14,\n",
       " 'journeyed': 15,\n",
       " 'took': 16,\n",
       " 'yes': 17,\n",
       " '?': 18,\n",
       " 'bathroom': 19,\n",
       " 'in': 20,\n",
       " 'travelled': 21,\n",
       " 'milk': 22,\n",
       " 'down': 23,\n",
       " 'grabbed': 24,\n",
       " 'is': 25,\n",
       " 'dropped': 26,\n",
       " 'john': 27,\n",
       " 'moved': 28,\n",
       " 'garden': 29,\n",
       " 'apple': 30,\n",
       " 'put': 31,\n",
       " '.': 32,\n",
       " 'kitchen': 33,\n",
       " 'picked': 34,\n",
       " 'hallway': 35,\n",
       " 'bedroom': 36,\n",
       " 'left': 37}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers_text = []\n",
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)\n",
    "    train_answers_text.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 28, 7, 2, 19, 32, 14, 15, 7, 2, 36, 32]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_story_seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(data,max_story_len=max_story_len,max_question_len=max_question_len):\n",
    "    story_text = []\n",
    "    question_text = []\n",
    "    answers_text = []\n",
    "    \n",
    "    for story,question,answer in data:\n",
    "        story_text.append(story)\n",
    "        question_text.append(question)\n",
    "        answer_array = np.zeros(len(vocab) + 1)\n",
    "        answer_array[tokenizer.word_index[answer]] = 1\n",
    "        answers_text.append(answer_array)\n",
    "        \n",
    "    story_seq = tokenizer.texts_to_sequences(story_text)\n",
    "    query_seq = tokenizer.texts_to_sequences(question_text)\n",
    "    \n",
    "    # Padding the sequences \n",
    "    return (pad_sequences(story_seq, maxlen=max_story_len),pad_sequences(query_seq, maxlen=max_question_len),np.array(answers_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answers_test = vectorize(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  2, 36, 32],\n",
       "       [ 0,  0,  0, ...,  2, 35, 32],\n",
       "       [ 0,  0,  0, ...,  2, 19, 32],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  2, 36, 32],\n",
       "       [ 0,  0,  0, ..., 22,  6, 32],\n",
       "       [ 0,  0,  0, ..., 30,  6, 32]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25, 14, 20,  2, 35, 18],\n",
       "       [25,  5, 20,  2, 19, 18],\n",
       "       [25,  5, 20,  2,  8, 18],\n",
       "       ...,\n",
       "       [25, 14, 20,  2, 35, 18],\n",
       "       [25,  1, 20,  2, 33, 18],\n",
       "       [25,  1, 20,  2, 36, 18]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  2, 36, 32],\n",
       "       [ 0,  0,  0, ...,  2, 29, 32],\n",
       "       [ 0,  0,  0, ...,  2, 29, 32],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  2, 30, 32],\n",
       "       [ 0,  0,  0, ...,  2, 29, 32],\n",
       "       [ 0,  0,  0, ..., 30,  6, 32]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 503.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0., 497.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from keras.layers import add, dot, concatenate\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders for Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Building the Networks\n",
    "\n",
    "The setup of neural network we'll use is chosen from this paper\n",
    "\n",
    "* Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus,\n",
    "  \"End-To-End Memory Networks\",\n",
    "  http://arxiv.org/abs/1503.08895"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoders\n",
    "\n",
    "### Input Encoder m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input gets embedded to a sequence of vectors\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "# This encoder will output:\n",
    "# (samples, story_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Encoder c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the input into a sequence of vectors of size query_maxlen\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "# output: (samples, story_maxlen, query_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the question into a sequence of vectors\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=64,\n",
    "                               input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "# output: (samples, query_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode input sequence and questions (which are indices)\n",
    "# to sequences of dense vectors\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use dot product to compute the match between first input vector seq and the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape: `(samples, story_maxlen, query_maxlen)`\n",
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add this match matrix with the second input vector sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
    "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the match matrix with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 6, 220) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce with RNN (LSTM)\n",
    "answer = LSTM(32)(answer)  # (samples, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization with Dropout\n",
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)\n",
    "\n",
    "# build the final model\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 156)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, None, 64)     2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 156, 6)       0           sequential[0][0]                 \n",
      "                                                                 sequential_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 156, 6)       0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, None, 6)      228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 156, 6)       0           activation[0][0]                 \n",
      "                                                                 sequential_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 6, 156)       0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 220)       0           permute[0][0]                    \n",
      "                                                                 sequential_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           32384       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32)           0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 38)           1254        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 38)           0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "313/313 [==============================] - 29s 16ms/step - loss: 1.2026 - accuracy: 0.4940 - val_loss: 0.6949 - val_accuracy: 0.5030\n",
      "Epoch 2/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.7078 - accuracy: 0.4958 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
      "Epoch 3/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.6953 - accuracy: 0.5066 - val_loss: 0.6936 - val_accuracy: 0.5030\n",
      "Epoch 4/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.6961 - accuracy: 0.4956 - val_loss: 0.6937 - val_accuracy: 0.4970\n",
      "Epoch 5/120\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.6948 - accuracy: 0.4889 - val_loss: 0.6944 - val_accuracy: 0.4970\n",
      "Epoch 6/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.6942 - accuracy: 0.5085 - val_loss: 0.6955 - val_accuracy: 0.4970\n",
      "Epoch 7/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.6951 - accuracy: 0.4889 - val_loss: 0.6936 - val_accuracy: 0.4970\n",
      "Epoch 8/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.6936 - accuracy: 0.5102 - val_loss: 0.6987 - val_accuracy: 0.4970\n",
      "Epoch 9/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.6935 - accuracy: 0.5148 - val_loss: 0.6944 - val_accuracy: 0.5030\n",
      "Epoch 10/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.6945 - accuracy: 0.5013 - val_loss: 0.6940 - val_accuracy: 0.4500\n",
      "Epoch 11/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.6952 - accuracy: 0.4945 - val_loss: 0.6943 - val_accuracy: 0.4970\n",
      "Epoch 12/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.6944 - accuracy: 0.4950 - val_loss: 0.6950 - val_accuracy: 0.4880\n",
      "Epoch 13/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.6933 - accuracy: 0.5094 - val_loss: 0.6957 - val_accuracy: 0.4910\n",
      "Epoch 14/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.6930 - accuracy: 0.5026 - val_loss: 0.6955 - val_accuracy: 0.4950\n",
      "Epoch 15/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.6904 - accuracy: 0.5301 - val_loss: 0.6900 - val_accuracy: 0.5150\n",
      "Epoch 16/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.6816 - accuracy: 0.5548 - val_loss: 0.6516 - val_accuracy: 0.6410\n",
      "Epoch 17/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.6330 - accuracy: 0.6459 - val_loss: 0.5625 - val_accuracy: 0.7300\n",
      "Epoch 18/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.5666 - accuracy: 0.7281 - val_loss: 0.5068 - val_accuracy: 0.7670\n",
      "Epoch 19/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.5136 - accuracy: 0.7707 - val_loss: 0.4690 - val_accuracy: 0.8080\n",
      "Epoch 20/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.4652 - accuracy: 0.7962 - val_loss: 0.4570 - val_accuracy: 0.7940\n",
      "Epoch 21/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.4504 - accuracy: 0.8087 - val_loss: 0.4296 - val_accuracy: 0.8290\n",
      "Epoch 22/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.4246 - accuracy: 0.8228 - val_loss: 0.4177 - val_accuracy: 0.8350\n",
      "Epoch 23/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.3941 - accuracy: 0.8364 - val_loss: 0.3998 - val_accuracy: 0.8360\n",
      "Epoch 24/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.3877 - accuracy: 0.8408 - val_loss: 0.3965 - val_accuracy: 0.8380\n",
      "Epoch 25/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.3825 - accuracy: 0.8395 - val_loss: 0.3913 - val_accuracy: 0.8400\n",
      "Epoch 26/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.3798 - accuracy: 0.8466 - val_loss: 0.3945 - val_accuracy: 0.8350\n",
      "Epoch 27/120\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.3835 - accuracy: 0.8367 - val_loss: 0.3813 - val_accuracy: 0.8440\n",
      "Epoch 28/120\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.3565 - accuracy: 0.8553 - val_loss: 0.3975 - val_accuracy: 0.8350\n",
      "Epoch 29/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.3505 - accuracy: 0.8577 - val_loss: 0.3798 - val_accuracy: 0.8350\n",
      "Epoch 30/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.3500 - accuracy: 0.8543 - val_loss: 0.3716 - val_accuracy: 0.8380\n",
      "Epoch 31/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.3618 - accuracy: 0.8520 - val_loss: 0.3785 - val_accuracy: 0.8440\n",
      "Epoch 32/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.3546 - accuracy: 0.8503 - val_loss: 0.3911 - val_accuracy: 0.8260\n",
      "Epoch 33/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.3401 - accuracy: 0.8621 - val_loss: 0.3563 - val_accuracy: 0.8410\n",
      "Epoch 34/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.3241 - accuracy: 0.8689 - val_loss: 0.3906 - val_accuracy: 0.8320\n",
      "Epoch 35/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.3230 - accuracy: 0.8655 - val_loss: 0.3644 - val_accuracy: 0.8350\n",
      "Epoch 36/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.3220 - accuracy: 0.8637 - val_loss: 0.3516 - val_accuracy: 0.8440\n",
      "Epoch 37/120\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.3235 - accuracy: 0.8625 - val_loss: 0.3848 - val_accuracy: 0.8360\n",
      "Epoch 38/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.3159 - accuracy: 0.8665 - val_loss: 0.3696 - val_accuracy: 0.8400\n",
      "Epoch 39/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.3266 - accuracy: 0.8594 - val_loss: 0.3655 - val_accuracy: 0.8380\n",
      "Epoch 40/120\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.3155 - accuracy: 0.8673 - val_loss: 0.3580 - val_accuracy: 0.8270\n",
      "Epoch 41/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.3080 - accuracy: 0.8680 - val_loss: 0.3471 - val_accuracy: 0.8390\n",
      "Epoch 42/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.3001 - accuracy: 0.8715 - val_loss: 0.3611 - val_accuracy: 0.8400\n",
      "Epoch 43/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.3026 - accuracy: 0.8741 - val_loss: 0.3627 - val_accuracy: 0.8390\n",
      "Epoch 44/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2985 - accuracy: 0.8703 - val_loss: 0.3553 - val_accuracy: 0.8400\n",
      "Epoch 45/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.3043 - accuracy: 0.8680 - val_loss: 0.3456 - val_accuracy: 0.8370\n",
      "Epoch 46/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2957 - accuracy: 0.8715 - val_loss: 0.3629 - val_accuracy: 0.8320\n",
      "Epoch 47/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.3027 - accuracy: 0.8714 - val_loss: 0.3698 - val_accuracy: 0.8350\n",
      "Epoch 48/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.3052 - accuracy: 0.8650 - val_loss: 0.3502 - val_accuracy: 0.8400\n",
      "Epoch 49/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2927 - accuracy: 0.8742 - val_loss: 0.3500 - val_accuracy: 0.8390\n",
      "Epoch 50/120\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.2908 - accuracy: 0.8741 - val_loss: 0.3390 - val_accuracy: 0.8400\n",
      "Epoch 51/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2907 - accuracy: 0.8757 - val_loss: 0.3515 - val_accuracy: 0.8370\n",
      "Epoch 52/120\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.2832 - accuracy: 0.8729 - val_loss: 0.3411 - val_accuracy: 0.8400\n",
      "Epoch 53/120\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.2864 - accuracy: 0.8780 - val_loss: 0.3588 - val_accuracy: 0.8360\n",
      "Epoch 54/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.2892 - accuracy: 0.8708 - val_loss: 0.3729 - val_accuracy: 0.8340\n",
      "Epoch 55/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2804 - accuracy: 0.8768 - val_loss: 0.3728 - val_accuracy: 0.8320\n",
      "Epoch 56/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2840 - accuracy: 0.8772 - val_loss: 0.3613 - val_accuracy: 0.8340\n",
      "Epoch 57/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2855 - accuracy: 0.8764 - val_loss: 0.3495 - val_accuracy: 0.8390\n",
      "Epoch 58/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2855 - accuracy: 0.8741 - val_loss: 0.3714 - val_accuracy: 0.8300\n",
      "Epoch 59/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2742 - accuracy: 0.8795 - val_loss: 0.3393 - val_accuracy: 0.8420\n",
      "Epoch 60/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2847 - accuracy: 0.8760 - val_loss: 0.3488 - val_accuracy: 0.8370\n",
      "Epoch 61/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2754 - accuracy: 0.8809 - val_loss: 0.3761 - val_accuracy: 0.8340\n",
      "Epoch 62/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2766 - accuracy: 0.8793 - val_loss: 0.3602 - val_accuracy: 0.8340\n",
      "Epoch 63/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2747 - accuracy: 0.8850 - val_loss: 0.3724 - val_accuracy: 0.8310\n",
      "Epoch 64/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2755 - accuracy: 0.8794 - val_loss: 0.3456 - val_accuracy: 0.8290\n",
      "Epoch 65/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2717 - accuracy: 0.8800 - val_loss: 0.3565 - val_accuracy: 0.8330\n",
      "Epoch 66/120\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.2610 - accuracy: 0.8872 - val_loss: 0.3562 - val_accuracy: 0.8330\n",
      "Epoch 67/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2685 - accuracy: 0.8808 - val_loss: 0.3515 - val_accuracy: 0.8450\n",
      "Epoch 68/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2687 - accuracy: 0.8854 - val_loss: 0.3705 - val_accuracy: 0.8310\n",
      "Epoch 69/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2605 - accuracy: 0.8865 - val_loss: 0.3548 - val_accuracy: 0.8290\n",
      "Epoch 70/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2614 - accuracy: 0.8864 - val_loss: 0.3858 - val_accuracy: 0.8330\n",
      "Epoch 71/120\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.2606 - accuracy: 0.8836 - val_loss: 0.3692 - val_accuracy: 0.8340\n",
      "Epoch 72/120\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.2719 - accuracy: 0.8797 - val_loss: 0.3603 - val_accuracy: 0.8360\n",
      "Epoch 73/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2579 - accuracy: 0.8915 - val_loss: 0.3822 - val_accuracy: 0.8260\n",
      "Epoch 74/120\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.2654 - accuracy: 0.8853 - val_loss: 0.3516 - val_accuracy: 0.8370\n",
      "Epoch 75/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2518 - accuracy: 0.8930 - val_loss: 0.3826 - val_accuracy: 0.8320\n",
      "Epoch 76/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2644 - accuracy: 0.8907 - val_loss: 0.3508 - val_accuracy: 0.8370\n",
      "Epoch 77/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2599 - accuracy: 0.8870 - val_loss: 0.3812 - val_accuracy: 0.8420\n",
      "Epoch 78/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2504 - accuracy: 0.8947 - val_loss: 0.3861 - val_accuracy: 0.8330\n",
      "Epoch 79/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2416 - accuracy: 0.8943 - val_loss: 0.3597 - val_accuracy: 0.8380\n",
      "Epoch 80/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2418 - accuracy: 0.8904 - val_loss: 0.3716 - val_accuracy: 0.8330\n",
      "Epoch 81/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2541 - accuracy: 0.8940 - val_loss: 0.3847 - val_accuracy: 0.8400\n",
      "Epoch 82/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2476 - accuracy: 0.8916 - val_loss: 0.3733 - val_accuracy: 0.8390\n",
      "Epoch 83/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2418 - accuracy: 0.8940 - val_loss: 0.3607 - val_accuracy: 0.8370\n",
      "Epoch 84/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2520 - accuracy: 0.8889 - val_loss: 0.4051 - val_accuracy: 0.8380\n",
      "Epoch 85/120\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.2504 - accuracy: 0.8908 - val_loss: 0.3704 - val_accuracy: 0.8410\n",
      "Epoch 86/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2403 - accuracy: 0.8956 - val_loss: 0.4405 - val_accuracy: 0.8290\n",
      "Epoch 87/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2344 - accuracy: 0.9023 - val_loss: 0.4219 - val_accuracy: 0.8250\n",
      "Epoch 88/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2446 - accuracy: 0.8983 - val_loss: 0.3972 - val_accuracy: 0.8360\n",
      "Epoch 89/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2350 - accuracy: 0.8994 - val_loss: 0.3907 - val_accuracy: 0.8360\n",
      "Epoch 90/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2503 - accuracy: 0.8895 - val_loss: 0.3787 - val_accuracy: 0.8330\n",
      "Epoch 91/120\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.2461 - accuracy: 0.8897 - val_loss: 0.3839 - val_accuracy: 0.8300\n",
      "Epoch 92/120\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.2290 - accuracy: 0.9053 - val_loss: 0.3861 - val_accuracy: 0.8440\n",
      "Epoch 93/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2356 - accuracy: 0.9001 - val_loss: 0.4247 - val_accuracy: 0.8330\n",
      "Epoch 94/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2352 - accuracy: 0.9007 - val_loss: 0.3866 - val_accuracy: 0.8450\n",
      "Epoch 95/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2331 - accuracy: 0.8995 - val_loss: 0.3879 - val_accuracy: 0.8220\n",
      "Epoch 96/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2288 - accuracy: 0.9046 - val_loss: 0.4290 - val_accuracy: 0.8340\n",
      "Epoch 97/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2293 - accuracy: 0.9017 - val_loss: 0.4046 - val_accuracy: 0.8400\n",
      "Epoch 98/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2199 - accuracy: 0.9025 - val_loss: 0.4202 - val_accuracy: 0.8410\n",
      "Epoch 99/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2224 - accuracy: 0.9064 - val_loss: 0.4065 - val_accuracy: 0.8400\n",
      "Epoch 100/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2251 - accuracy: 0.9013 - val_loss: 0.3930 - val_accuracy: 0.8450\n",
      "Epoch 101/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2356 - accuracy: 0.9031 - val_loss: 0.4649 - val_accuracy: 0.8320\n",
      "Epoch 102/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2290 - accuracy: 0.9039 - val_loss: 0.4153 - val_accuracy: 0.8480\n",
      "Epoch 103/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2338 - accuracy: 0.8953 - val_loss: 0.4390 - val_accuracy: 0.8360\n",
      "Epoch 104/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2315 - accuracy: 0.8996 - val_loss: 0.4385 - val_accuracy: 0.8360\n",
      "Epoch 105/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2233 - accuracy: 0.9025 - val_loss: 0.4235 - val_accuracy: 0.8430\n",
      "Epoch 106/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2235 - accuracy: 0.9006 - val_loss: 0.4338 - val_accuracy: 0.8390\n",
      "Epoch 107/120\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.2140 - accuracy: 0.9072 - val_loss: 0.4781 - val_accuracy: 0.8360\n",
      "Epoch 108/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2134 - accuracy: 0.9099 - val_loss: 0.4422 - val_accuracy: 0.8430\n",
      "Epoch 109/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2150 - accuracy: 0.9057 - val_loss: 0.4223 - val_accuracy: 0.8340\n",
      "Epoch 110/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2017 - accuracy: 0.9135 - val_loss: 0.4700 - val_accuracy: 0.8330\n",
      "Epoch 111/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2074 - accuracy: 0.9111 - val_loss: 0.4888 - val_accuracy: 0.8270\n",
      "Epoch 112/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2150 - accuracy: 0.9078 - val_loss: 0.4508 - val_accuracy: 0.8370\n",
      "Epoch 113/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2074 - accuracy: 0.9081 - val_loss: 0.4790 - val_accuracy: 0.8350\n",
      "Epoch 114/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.1961 - accuracy: 0.9158 - val_loss: 0.4241 - val_accuracy: 0.8400\n",
      "Epoch 115/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.1987 - accuracy: 0.9120 - val_loss: 0.4987 - val_accuracy: 0.8410\n",
      "Epoch 116/120\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.2084 - accuracy: 0.9110 - val_loss: 0.5386 - val_accuracy: 0.8280\n",
      "Epoch 117/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2073 - accuracy: 0.9105 - val_loss: 0.4569 - val_accuracy: 0.8340\n",
      "Epoch 118/120\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.2042 - accuracy: 0.9093 - val_loss: 0.4273 - val_accuracy: 0.8360\n",
      "Epoch 119/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.1978 - accuracy: 0.9128 - val_loss: 0.4383 - val_accuracy: 0.8380\n",
      "Epoch 120/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.1942 - accuracy: 0.9156 - val_loss: 0.4200 - val_accuracy: 0.8390\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=120,validation_data=([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "filename = 'mine_chatbot_120_epochs.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'got',\n",
       "  'the',\n",
       "  'milk',\n",
       "  'there',\n",
       "  '.',\n",
       "  'John',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'John', 'in', 'the', 'kitchen', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True answer of first question is no, based on story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.48960835e-17, 1.54994655e-17, 1.50033540e-17, 1.72705336e-17,\n",
       "       1.40081564e-17, 1.53353793e-17, 1.24488978e-17, 1.44065299e-17,\n",
       "       1.81178759e-17, 1.58962872e-17, 9.99996662e-01, 1.41005327e-17,\n",
       "       1.85367784e-17, 1.41293367e-17, 1.24361774e-17, 1.62973589e-17,\n",
       "       1.41157081e-17, 3.33792786e-06, 1.59397638e-17, 1.65679678e-17,\n",
       "       1.50237440e-17, 1.67769549e-17, 1.42029393e-17, 1.64855690e-17,\n",
       "       1.52580032e-17, 1.40460942e-17, 1.73469932e-17, 1.44944526e-17,\n",
       "       1.37631249e-17, 1.61732471e-17, 1.26881855e-17, 1.33968451e-17,\n",
       "       1.53739789e-17, 1.57904593e-17, 1.54532972e-17, 1.37749957e-17,\n",
       "       1.54985787e-17, 1.46444006e-17], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(pred_results[0])\n",
    "pred_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results[0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Answer is 'no'\n",
      "Probability of certainity is 0.99999666\n"
     ]
    }
   ],
   "source": [
    "for word in vocab:\n",
    "    word = word.lower()\n",
    "    if tokenizer.word_index[word]==pred_results[0].argmax():\n",
    "        print(\"Predicted Answer is \" +\"'\"+str(word)+\"'\")\n",
    "        print('Probability of certainity is ' + str(pred_results[0].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing our own stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story = 'Mary moved to garden . Daniel put milk in kitchen .'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_query = 'Is Milk in the kitchen ?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ans = 'yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_testing = [(my_story.split(),my_query.split(),my_ans)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story,my_ques,my_ans = vectorize(my_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  yes\n",
      "Probability of certainty was:  0.89285517\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
